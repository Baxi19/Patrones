# TensorFlow y Keras

# 游눹 쯈u칠 es Keras en comparaci칩n con TensorFlow y cu치l es su prop칩sito?

Tensorflow es la biblioteca m치s famosa utilizada en producci칩n para modelos de aprendizaje profundo. Tiene una comunidad muy grande e impresionante. La cantidad de confirmaciones y la cantidad de ejemplos en el repositorio de Tensorflow en Github son suficientes para definir la amplia popularidad de TensorFlow. Sin embargo, TensorFlow no es tan f치cil de usar. Por otro lado, Keras es una API de alto nivel construida sobre Tensorflow  adem치s es m치s f치cil de usar y f치cil de usar en comparaci칩n con TensorFlow. Keras es una librer칤a la cual se encuentra escrita en Python, es utilizada para machine learning, especialmente con las redes neuronales , cabe resaltar que esta librer칤a es de c칩digo abierto y  tiene la posibilidad de conectarse con TensorFlow y otras librer칤as enfocadas en aprendizaje profundo, el prop칩sito de Keras es facilitar el uso de los modelos de machine learning [1].

---

# 游놀游낕游눹  쯇or qu칠 TensorFlow usa grafos y c칩mo se crean manualmente?

TensorFlow utiliza grafos para representar las redes neuronales en una estructura de datos.

**Creando grafos en TensorFlow 2**

Para iniciar se muestra de ejemplo de la creaci칩n de un grafo en Python.

```python
def compute(a,b,c):
	d = a*b+c
	e = a*b*c
	return d,e
```

Asumiendo que a, b y c son matrices de Tensor, este c칩digo calcula dos nuevos valores: d y e. Usando la ejecuci칩n **aeger**, TensorFlow podr칤a calcular el valor para d y despu칠s calcular el valor para e.

Usando la ejecuci칩n **lazy**, TensorFlow crear칤a un grafo de operaciones, antes de ejecutar el grafo para obtener el resultado, se ejecutar칤a un optimizador de grafos. Para evitar calcular a * b dos veces, el optimizador almacenar칤a en cach칠 el resultado y lo reutilizar칤a cuando fuera necesario. Para operaciones m치s complejas, el optimizador podr칤a permitir el paralelismo para acelerar los c치lculos. Ambas t칠cnicas son importantes al ejecutar modelos grandes y complejos [2].

---

# 游눹쮺u치l es la diferencia entre el modo de ejecuci칩n "Eager" y el modo de ejecuci칩n "Lazy"?

El cambio principal en TensorFlow 2 es la ejecuci칩n **eager**. Hist칩ricamente, TensorFlow 1 siempre ha usado la ejecuci칩n **lazy** por defecto. Se llama perezoso porque el framework no ejecuta las operaciones hasta que se solicita espec칤ficamente.

En el cap칤tulo "TensorFlow Basics and Trainning", se hace menci칩n a un ejemplo que ilustra la diferencia entre la ejecuci칩n **lazy** y **eager,** sumando el valor de dos vectores:

```python
import tensorflow as tf

a = tf.constant([1,2,3])
b = tf.constant([0,0,1])
c = tf.add(a,b)`
```

N칩tese que `tf.add(a. b)` se podr칤a remplazar con a + b ya que TensorFlow sobre escribe muchos de los operadores de Python.

El resultado del c칩digo anterior depende de la versi칩n de TensorFlow. Con TensorFlow 1 que usa la ejecuci칩n lazy por defecto, el resultado ser칤a el siguiente:

```python
Tensor("Add:0, shape = (3, ), dtype=int32)
```

Usando TensorFlow 2, que implementa la ejecuci칩n eager por defecto, se podr칤a tener la siguiente la siguiente salida:

```python
tf.Tensor([1 2 4]), shape = (3, ), dtype=int32)
```

En ambos casos, la salida es un Tensor. En el segundo caso, la operaci칩n ha sido ejecutada ansiosamente y podemos ver directamente que el Tensor contiene el resultado (`[1 2 3 ]`). En el primer caso, el Tensor contiene informaci칩n de la operaci칩n suma (`Add : 0`), pero no el resultado de la operaci칩n.

---

# 游댍 쮺칩mo registra la informaci칩n en TensorBoard y c칩mo la muestra?

TensorBoard es un componente de TensorFlow, registra la informaci칩n de diferentes escalares, im치genes, histogramas, etc, en archivos con formato **`tf.summary`**, adem치s cabe resaltar que para mostrar la informaci칩n se puede graficar de diferentes maneras, ya sea en el momento de la ejecuci칩n, entrada o salida de im치genes, entre otros.

---

# 游닄 쮺u치les son las principales diferencias entre TensorFlow 1 y TensorFlow 2?

En TensorFlow 1, se podr칤a de necesitar m치s c칩digo para calcular el resultado de operaciones entre grafos, haciendo el proceso de desarrollo m치s complejo. La ejecuci칩n **aeger** implementada en TensorFlow 2 hace que el proceso de debug sea m치s sencillo, ya que los desarrolladores pueden alcanzar el punto m치ximo del valor del Tensor en cualquier momento, propiciando un desarrollo m치s f치cil.

---

# 游닆 Referencias Bibliogr치ficas

[1] Nain, A. (2017, 13 mayo). TensorFlow or Keras? Which one should I learn? Recuperado 13 de octubre de 2020, de [https://medium.com/implodinggradients/tensorflow-or-keras-which-one-should-i-learn-5dd7fa3f9ca0](https://medium.com/implodinggradients/tensorflow-or-keras-which-one-should-i-learn-5dd7fa3f9ca0)

[2] Benjamin Planche & Eliot Andres, 30 may. 2019,Hands-On Computer Vision with TensorFlow 2: Leverage deep learning to create powerful image processing apps with TensorFlow 2.0 and Keras, Cap칤tulo 2: TensorFlow basics and training model, p치ginas 50-73. extra칤do de [https://app.box.com/s/7d8z6ofzs9twin728k1cnc987ja0hmd7](https://app.box.com/s/7d8z6ofzs9twin728k1cnc987ja0hmd7)